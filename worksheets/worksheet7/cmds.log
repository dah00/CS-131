   45  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | tail -30
   46  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | head -30
   47  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F '{if($1>=3) {print}}' |  head -30
   48  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' |  head -30
   49  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' 
   50  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' | wc -c
   51  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' | wc -b
   52  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' | wc 
   53  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' | wc -l
   54  cd /etc/gnuplot-5.4.4/src/
   55  ./gnuplot 
   56  cd ..
   57  cd ~
   58  cd workplace
   59  cd assignments
   60  cd a3
   61  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' > Q2.csv
   62  ls
   63  pwd
   64  cd gnuplot-5.4.2/
   65  cd src
   66  ls
   67  cp ../../Q2.csv .
   68  ls
   69  ./gnuplot 
   70  cd ..
   71  cat Q2.csv 
   72  awk -F " " '{print $2}'
   73  awk -F " " '{print $2}' Q2.csv 
   74  awk -F " " '{print $2}' Q2.csv > q2.csv
   75  cat q2.csv 
   76  cd gnuplot-5.4.2/
   77  cd src
   78  cp ../../q2.csv .
   79  ls
   80  ./gnuplot 
   81  cd ..
   82  cd a2
   83  ls
   84  tail -5 a2.txt
   85  tail -15 a2.txt
   86  tail -25 a2.txt
   87  exit
   88  cd ..
   89  cd a2
   90  tail -30 a2.txt 
   91  tail -40 a2.txt 
   92  cat a2.txt 
   93  exit
   94  exit
   95  awk-F '\t' '$6!=""' downloaded_tweets_extend_original_nolf2.tsv | awk -F '\t' '{print $6 "," $2}' | sort -k 1n > Q1.csv
   96  awk -F '\t' '$6!=""' downloaded_tweets_extend_original_nolf2.tsv | awk -F '\t' '{print $6 "," $2}' | sort -k 1n > Q1.csv
   97  head -10 Q1.csv 
   98  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1rn | awk -F " " '{if($1>=3) {print}}' | wc -l
   99  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1rn | awk -F " " '{if($1>=3) {print}}' > Q1.csv
  100  cat Q1.csv 
  101  awk -F '\t' '$6!=""' downloaded_tweets_extend_original_nolf2.tsv | awk -F '\t' '{print $6 "," $2}' | sort -k 1n > Q1.csv
  102  head -10 Q1.csv 
  103  awk -F, '{if($1!=$2) {print}}' Q1.csv | uniq -c | sort -k 1rn | awk -F " " '{if($1>=3) {print}}' > Q2.csv
  104  head -10 Q2.csv 
  105  grep -e '\[*replied_to\]' downloaded_tweets_extend_original_nolf2.tsv | cut -d "	" -f4 | sort | uniq -c | sort -rn | head -31 > Q4.tsv
  106  head -10 Q4.tsv 
  107  cut -d "	" -f4 downloaded_tweets_extend_nolf2.tsv | sort | uniq -c | sort -rn | head -31 > Q5_a2.tsv
  108  head -10 Q5_a2.tsv 
  109  diff Q4.tsv Q5_a2.tsv 
  110  cat Q1.csv 
  111  cat Q2.csv 
  112  cat Q4.tsv 
  113  cd workplace
  114  cd assignments
  115  cd a3
  116  cat q2.csv
  117  cd gnuplot-5.4.2/src/
  118  ./gnuplot 
  119  ls
  120  cd ..
  121  head -10 downloaded_tweets_extend_original_nolf2.tsv 
  122  grep 1045329516762030080 downloaded_tweets_extend_original_nolf2.tsv
  123  head -10 downloaded_tweets_extend_original_nolf2.tsv 
  124  awk -F "\t" '{print $5}' downloaded_tweets_extend_original_nolf2.tsv | head -20
  125  awk -F "\t" '{print $5}' downloaded_tweets_extend_original_nolf2.tsv | head -60
  126  awk -F "\t" '{print $5}' downloaded_tweets_extend_original_nolf2.tsv | tail -60
  127  tmux 
  128  cut -d "\t" -f4 downloaded_tweets_extend_original_nolf2.tsv | tail -60
  129  cut -d "	" -f4 downloaded_tweets_extend_original_nolf2.tsv | tail -60
  130  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv | tail -40
  131  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv | head -40
  132  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | sort | uniq -c |sort -rn | head -31
  133  cd ..
  134  cd a2
  135  cat a2.txt 
  136  cd ..
  137  cd a3
  138  grep -e '\[*retweeted\]' downloaded_tweets_extend_original_nolf2.tsv | cut -d "	" -f5 | sort | uniq -c | sort -rn | head -31
  139  grep -e '\[*retweeted\]' downloaded_tweets_extend_original_nolf2.tsv | head -31
  140  grep -e '\[*repliedto\]' downloaded_tweets_extend_original_nolf2.tsv | head -31
  141  grep -e '\[*replied_to\]' downloaded_tweets_extend_original_nolf2.tsv | head -31
  142  grep -e '\[*replied_to\]' downloaded_tweets_extend_original_nolf2.tsv | cut -d "	" -f5 | sort | uniq -c | sort -rn | head -31
  143  head -5 downloaded_tweets_extend_original_nolf2.tsv 
  144  grep -e '\[*replied_to\]' downloaded_tweets_extend_original_nolf2.tsv | cut -d "	" -f4 | sort | uniq -c | sort -rn | head -31
  145  grep -e '\[*replied_to\]' downloaded_tweets_extend_original_nolf2.tsv | cut -d "	" -f4 | sort | uniq -c | sort -rn | head -31 > q4_30Mosthastags.tsv
  146  cut -d "	" -f4 downloaded_tweets_extend_nolf2.tsv | sort | uniq -c | sort -rn | head -31
  147  cut -d "	" -f4 downloaded_tweets_extend_nolf2.tsv | sort | uniq -c | sort -rn | head -31 > q5_a2.tsv
  148  diff q4_30Mosthastags.tsv q5_a2.tsv 
  149  ls
  150  rm Q1.csv 
  151  rm q2.csv 
  152  rm Q2.csv 
  153  rm q4_30Mosthastags.tsv 
  154  rm q5_a2.tsv 
  155  script a3.txt
  156  ls
  157  cat Q1.csv | wc -l
  158  vi Q1.csv 
  159  vi a3.txt 
  160  cat a3.txt 
  161  git status
  162  git add a3.txt
  163  git status
  164  git commit -m "submit assigment3"
  165  git push 
  166  exit
  167  ls
  168  cd workplace
  169  cd assignments
  170  cd a3
  171  ls
  172  mkdir ../../../datafiles
  173  mv downloaded_tweets_extend_original_nolf2.tsv ../../../datafiles
  174  mv downloaded_tweets_extend_nolf2.tsv ../../../datafiles
  175  ls
  176  cd ..
  177  cd..
  178  cd ..
  179  ls
  180  mv amazon_reviews_us_Books_v1_02.tsv datafiles
  181  ls
  182  cd datafiles
  183  ls
  184  cd ..
  185  cd workplace/worksheets
  186  ls
  187  mkrdir worksheet5
  188  mkdir worksheet5
  189  ls
  190  cd worksheet5
  191  cp ../../../datafiles/amazon_reviews_us_Books_v1_02.tsv .
  192  ls
  193  exit
  194  head /etc/passwd
  195  vi test
  196  awk -f test /etc/passwd
  197  vi test
  198  cat test
  199  vi
  200  vi test
  201  awk -f test /etc/passwd
  202  vi test
  203  awk -f test /etc/passwd
  204  vi test
  205  awk -f test /etc/passwd
  206  vi test
  207  awk -f test /etc/passwd
  208  cd workplace
  209  cd worksheets
  210  ls
  211  cd worksheet5
  212  ls
  213  head -5 amazon_reviews_us_Books_v1_02.tsv 
  214  head -2 amazon_reviews_us_Books_v1_02.tsv 
  215  tmux new -s ws5
  216  cd workplace
  217  cd worksheets
  218  cd worksheet5
  219  tmux -l
  220  cd workplace
  221  cd worksheets
  222  cd worksheet5
  223  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | sort | uniq -c | sort -rn | head -5
  224  grep 50122160 amazon_reviews_us_Books_v1_02.tsv 
  225  grep 50122160 amazon_reviews_us_Books_v1_02.tsv  | head -5
  226  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | sort | uniq -c | sort -rn | head -5
  227  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | sort | uniq -c | sort -rn > top1000cust.tsv
  228  cat top1000cust.tsv | wc -l
  229  rm top1000cust.tsv 
  230  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | sort | uniq -c | sort -rn | head -1000> top1000cust.tsv
  231  cat top1000cust.tsv | wc -l
  232  head top1000cust.tsv 
  233  vi awkscp_array
  234  cat awkscp_array 
  235  awk -f awkscp_array top1000cust.tsv 
  236  vi
  237  vi awkscp_array
  238  awk -f awkscp_array top1000cust.tsv 
  239  vi awkscp_array
  240  cat awkscp_array 
  241  vi awkscp_array 
  242  cat awkscp_array 
  243  awk -f awkscp_array top1000cust.tsv 
  244  ls
  245  cd workplace/worksheets/worksheet5
  246  ls
  247  mkdir CUSTOMERS
  248  cd CUSTOMERS/
  249  cat ../awkscp_array 
  250  awk 'BEGIN {FS=" "} {system("grep $2 amazon_reviews_us_Books_v1_02.tsv > $2.txt")}'
  251  awk 'BEGIN {FS=" "} {system("grep $2 amazon_reviews_us_Books_v1_02.tsv > $2.txt")}' ../awkscp_array 
  252  ls workplace/worksheets/worksheet5
  253  cd workplace/worksheets/worksheet5
  254  cd CUSTOMERS
  255  LS
  256  ls
  257  cd workplace/worksheets
  258  cd worksheet5
  259  ls
  260  cd CUSTOMERS
  261  ls
  262  cd ..
  263  tail top1000cust.tsv 
  264  grep 33113980 amazon_reviews_us_Books_v1_02.tsv | tail
  265  awk '{system("grep 33113980 amazon_reviews_us_Books_v1_02.tsv > 33113980.txt")}' 
  266  vi awkscp_array 
  267  cat awkscp_array 
  268  awk -f awkscp_array top1000cust.tsv 
  269  vi awkscp_array 
  270  cat awkscp_array 
  271  awk -f awkscp_array top1000cust.tsv 
  272  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | sort | uniq -c | sort -rn | head -1000 > top1000cust.tsv
  273  cat top1000cust.tsv | wc -l
  274  vi bashscript.sh
  275  cat bashscript.sh 
  276  ./bashscript.sh
  277  chmod 744 bashscript.sh 
  278  cd CUSTOMERS
  279  ls
  280  cd ..
  281  cd workplace/worksheets
  282  cd worksheet5
  283  vi awkscp_array 
  284  cat awkscp_array 
  285  awk -f awkscp_array top1000cust.tsv 
  286  vi awkscp_array 
  287  awk -f awkscp_array top1000cust.tsv 
  288  vi awkscp_array 
  289  cat awkscp_array 
  290  awk -f awkscp_array top1000cust.tsv 
  291  vi awkscp_array 
  292  awk -f awkscp_array top1000cust.tsv 
  293  vi awkscp_array 
  294  awk -f awkscp_array top1000cust.tsv 
  295  vi awkscp_array 
  296  awk -f awkscp_array top1000cust.tsv 
  297  vi awkscp_array 
  298  awk -f awkscp_array top1000cust.tsv 
  299  vi awkscp_array 
  300  awk -f awkscp_array top1000cust.tsv 
  301  ls
  302  rm 33113980.txt 
  303  awk -f awkscp_array top1000cust.tsv 
  304  ls
  305  tail top1000cust.tsv 
  306  vi test
  307  ls
  308  for id in test; do grep "$id" amazon_reviews_us_Books_v1_02.tsv done ; test; 
  309  vi testawk
  310  ls -l
  311  ls -latr
  312  vi testawk 
  313  awk -f testawk 
  314  vi testawk
  315  ./testawk.sh
  316  testawk.sh
  317  ./testawk.sh
  318  rm testawk 
  319  ls
  320  rm test
  321  ls
  322  vi awkscp_array 
  323  awk '{"date"}'
  324  ls
  325  vi awkscp_array 
  326  vi scr.sh
  327  cat scr.sh
  328  vi scr.sh 
  329  ./scr.sh
  330  chmod 744 scr.sh
  331  ./scr.sh
  332  ls
  333  cd CUSTOMERS
  334  ls
  335  cat top1000custid.txt.txt 
  336  rm top1000custid.txt.txt 
  337  cd ..
  338  vi scr.sh 
  339  vi awkscp_array 
  340  vi scr.sh 
  341  ./scr.sh
  342  cd CUSTOMERS
  343  ls
  344  cd ..
  345  ls
  346  vi scr.sh
  347  ./scr.sh
  348  ls
  349  vi scr.sh 
  350  vi test.sh
  351  chmod test.sh
  352  chmod 744 test.sh
  353  ./test.sh 
  354  vi scr.sh 
  355  ./scr.sh 
  356  vi scr.sh 
  357  ./scr.sh 
  358  ls
  359  ./scr.sh 
  360  vi src.sh
  361  ls
  362  vi scr.sh 
  363  ./scr.sh 
  364  vi scr.sh 
  365  ./scr.sh 
  366  vi scr.sh 
  367  ./scr.sh 
  368  cut -d ' ' -f2 top1000cust.tsv | head
  369  head top1000cust.tsv 
  370  cut -d ' ' -f2 top1000cust.tsv | head
  371  cut -d ' ' -f 2 top1000cust.tsv | head
  372  cut -d " " -f 1 top1000cust.tsv | head
  373  cut -d " " -f3 top1000cust.tsv | head
  374  head top1000cust.tsv 
  375  awk -F " " $2
  376  awk -F " " '{print $2}' top1000cust.tsv 
  377  awk -F " " '{print $2}' top1000cust.tsv | head
  378  head top1000cust.tsv 
  379  vi scr.sh 
  380  ./scr.sh 
  381  vi scr.sh 
  382  ./scr.sh 
  383  cd CUSTOMERS
  384  ls
  385  cd ..
  386  vi scr.sh 
  387  ls
  388  rm test.sh
  389  rm src.sh
  390  rm top1000cust.tsv 
  391  cat awkscp_array 
  392  rm arm awkscp_array 
  393  ls
  394  rm scr.sh 
  395  script ws5.txt
  396  vi ws5.txt
  397  history >cmds.log
  398  ls
  399  git status
  400  git add ws5.txt
  401  git add cmds.log
  402  git status
  403  git commit -m "submit worksheet5"
  404  git push 
  405  git status
  406  ls 
  407  git add ws5.txt
  408  git add cmds.log
  409  git status
  410  git push origin main
  411  git status
  412  cd workplace/worksheets/worksheet5
  413  ls
  414  git status
  415  git push origin main
  416  git push main
  417  cd ..
  418  git status
  419  git pull
  420  git push main
  421  git push origin main
  422  ls
  423  DATETIME=`date "+%Y%m%d_%H%M%S"`
  424  echo "$DATETIME"
  425  cp ../../assignments/a2/PRODUCTS/1576734587.txt PRODUCTS/1576734587.$DATETIME.txt
  426  cd PRODUCTS
  427  ls
  428  ls -l
  429  cd ..
  430  rm PRODUCTS
  431  rm -d PRODUCTS
  432  rm -r PRODUCTS
  433  mkdir PRODUCTS
  434  cp ../../assignments/a2/PRODUCTS/1576734587.txt PRODUCTS/1576734587.$DATETIME.txt
  435  ls PRODUTS/
  436  ls PRODUCTS/
  437  awk 'BEGIN {FS = OFS = "\t"} {print $0, "4"}' PRODUCTS/1576734587.20221019_220821.txt  > PRODUCTS/1576734587.20221019_220821.txt 
  438  head -2 PRODUCTS/1576734587.20221019_220821.txt 
  439  cd PRODUCTS
  440  head -2 1576734587.20221019_220821.txt 
  441  cd ..
  442  cp ../../assignments/a2/PRODUCTS/1576734587.txt PRODUCTS/1576734587.$DATETIME.txt
  443  cd PRODUCTS
  444  head -2 1576734587.20221019_220821.txt 
  445  awk 'BEGIN {FS = OFS = "\t"} {print $0, "4"}' PRODUCTS/1576734587.20221019_220821.txt  > temp && mv tmp PRODUCTS/1576734587.20221019_220821.txt
  446  cd ..
  447  awk 'BEGIN {FS = OFS = "\t"} {print $0, "4"}' PRODUCTS/1576734587.20221019_220821.txt  > temp && mv tmp PRODUCTS/1576734587.20221019_220821.txt
  448  awk 'BEGIN {FS = OFS = "\t"} {print $0, "4"}' PRODUCTS/1576734587.20221019_220821.txt  > PRODUCTS/1576734587.20221019_220821.txt
  449  cd PRODUCTS
  450  head -2 1576734587.20221019_220821.txt 
  451  LS
  452  ls
  453  cat 1576734587.20221019_220821.txt 
  454  rm temp
  455  rm 1576734587.20221019_220821.txt 
  456  cd ..
  457  cp ../../assignments/a2/PRODUCTS/1576734587.txt PRODUCTS/1576734587.$DATETIME.txt
  458  awk 'BEGIN {FS = OFS = "\t"} {print $0, "4"}' PRODUCTS/1576734587.20221019_220821.txt
  459  ln -s PRODUCTS/1576734587.$DATETIME.txt PRODUCTS/1576734587.LATEST.txt 
  460  ls PRODUCTS
  461  vi cal_average.sh
  462  cat cal_average.sh 
  463  vi cal_average.sh 
  464  cat cal_average.sh 
  465  vi cal_average.sh 
  466  cd PRODUCTS
  467  crontab -e
  468  crontab -l
  469  cd ..
  470  vi cal_average.sh 
  471  crontab -l
  472  crontab -e
  473  ls
  474  cat cal_average.sh 
  475  crontab -l
  476  exit
  477  crontab -l
  478  tmux new -s ws6
  479  exit
  480  head -2 amazon_reviews_us_Books_v1_02.tsv 
  481  awk -F '\t' '{print $2}' | head 5
  482  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | head 5
  483  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | head -5
  484  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c | sort -rn | head -5
  485  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | head -5
  486  awk -F '\t' '{print $2}' amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c | sort -rn | wc -l
  487  ls
  488  cd test
  489  rm test
  490  ls workplace/worksheets
  491  mkdir workplace/worksheets/worksheet6
  492  cp datafiles/amazon_reviews_us_Books_v1_02.tsv workplace/worksheets/worksheet6
  493  cd workplace/worksheets/worksheet6
  494  ls
  495  head -2 amazon_reviews_us_Books_v1_02.tsv 
  496  echo $date
  497  echo $(date)
  498  echo `date`
  499  echo "$date"
  500  $DATETIME=`date`
  501  $DATETIME=$(date)
  502  DATETIME=$(date)
  503  echo "DATETIME"
  504  echo "$DATETIME"
  505  mkdir PRODUCTS
  506  cp ../../assignments/PRODUCTS/1576734587.txt ./PRODUCTS/1576734587.$DATETIME.txt
  507  cd ..
  508  cd worksheets
  509  cd worksheet6
  510  cp ../../assignments/a2/PRODUCTS/1576734587.txt ./PRODUCTS/1576734587.$DATETIME.txt
  511  ls
  512  cp ../../assignments/a2/PRODUCTS/1576734587.txt PRODUCTS/1576734587.$DATETIME.txt
  513  unset DATETIME
  514  echo "$DATETIME"
  515  DATETIME = "TEST"
  516  DATETIME="TEST"
  517  echo "$DATETIME"
  518  unset DATETIME
  519  DATETIME=`date "+%Y%m%d_%H%M%S"`
  520  date
  521  echo "$DATETIME"
  522  cp ../../assignments/a2/PRODUCTS/1576734587.txt PRODUCTS/1576734587.$DATETIME.txt
  523  ls 
  524  cd PRODUCTS
  525  ls
  526  cd ..
  527  head -1 amazon_reviews_us_Books_v1_02.tsv 
  528  head -2 amazon_reviews_us_Books_v1_02.tsv 
  529  vi PRODUCTS/1576734587.20221019_200243.txt 
  530  cat PRODUCTS/1576734587.20221019_200243.txt 
  531  vi PRODUCTS/1576734587.20221019_200243.txt 
  532  ln -s PRODUCTS/1576734587.20221019_200243.txt PRODUCTS/1576734587.LATEST.txt 
  533  ls
  534  cd PRODUCTS
  535  ls
  536  ls -latr
  537  cd ..
  538  crontab question5
  539  crontab -e question5
  540  crontab -e 
  541  crontab -e obeda
  542  crontab -e 
  543  crontab -l
  544  vi cal_average.sh
  545  ls
  546  script ws6.txt
  547  history > cmds.log
  548  ls
  549  git status
  550  ls
  551  git add cmds.log w6.txt
  552  git add cmds.log ws6.txt
  553  git status
  554  git commit -m "Submitting worksheet6"
  555  git push 
  556  cd workplace/assignmnets
  557  cd workplace/assignments
  558  cd assignment2
  559  ls
  560  cd a2
  561  ls
  562  cd ..
  563  cd a3
  564  ls
  565  cd .. 
  566  cd a2
  567  ls
  568  head -7 a2.txt 
  569  head -30 a2.txt 
  570  head -35 a2.txt 
  571  cp ../../../datafiles/amazon_reviews_us_Books_v1_02.tsv .
  572  awk -F "\t" '{print $4}' amazon_reviews_us_Books_v1_02.tsv  | sort | uniq -c | sort -n -r | head -n 100  > top100products
  573  ls
  574  hea
  575  head -10 top100products 
  576  mkdir PRODUCTS
  577  for i in `cat top100products | awk '{print $2}'` ; do echo "$i"; grep $i amazon_reviews_us_Books_v1_02.tsv | awk -F "\t" '{print $8,$9}' > PRODUCTS/$i.txt   ; done
  578  ls
  579  cd PRODUCTS
  580  ls | wc -l
  581  ls | head -10
  582  cat 0060193395.txt
  583  ls | head -5
  584  cat 0060392452.txt | wc -l
  585  cat 0060582510.txt | wc -l
  586  cat 0060761288.txt | wc -l
  587  cat 0060582510.txt | wc -l
  588  ls | head -10
  589  cat 0060938455.txt | wc -l
  590  cat 0060930535.txt | wc -l
  591  cat 0060928336.txt | wc -l
  592  ls | tail -10
  593  cat 1594480001.txt | wc -l
  594  cat 1576734587.txt | wc -l
  595  cd ..
  596  grep 1576734587.txt amazon_reviews_us_Books_v1_02.tsv 
  597  ls
  598  grep 1576734587 amazon_reviews_us_Books_v1_02.tsv 
  599  ls
  600  grep 1576734587 amazon_reviews_us_Books_v1_02.tsv | head -1
  601  grep 1576734587 amazon_reviews_us_Books_v1_02.tsv | head -1 > 1576734587.txt
  602  ls
  603  cat 1576734587.txt 
  604  cd PRODUCTS
  605  grep 1576734587 .
  606  grep 1576734587 
  607  cd ..
  608  grep 1576734587 PRODUCTS
  609  move PRODUCTS PRODUCTS_old
  610  mv PRODUCTS PRODUCTS_old
  611  ls
  612  mkdir PRODUCTS
  613  mv 1576734587.txt PRODUCTS/
  614  LS
  615  ls
  616  ls PRODUCTS
  617  rm PRODUCTS/1576734587.txt 
  618  cd PRODUCTS
  619  grep 1576734587 ../amazon_reviews_us_Books_v1_02.tsv > 1576734587.txt
  620  ls
  621  cat 1576734587.txt 
  622  awk 'BEGIN {FS = OFS = "\t"} {print $0, "NewColumn"}' 1576734587.txt 
  623  head -3 1576734587.txt 
  624  awk 'BEGIN {FS = OFS = "\t"} {print $0, "5"}' 1576734587.txt 
  625  head -3 1576734587.txt 
  626  head -1 1576734587.txt 
  627  cd ..
  628  worksheets
  629  cd worksheets
  630  cd worksheet6
  631  ls
  632  cd workplace/assignments
  633  cls
  634  ls
  635  mkdir a4
  636  cd a4
  637  cp /home/test/A1/downloaded_tweets_extend_original_nolf2.tsv .
  638  ls
  639  cp /home/test/A1/downloaded_tweets_extend_nolf2.tsv .
  640  ls
  641  ls ../../../datafiles
  642  tmux -l
  643  tmux ls
  644  tmux kill-session -a
  645  tmux ls
  646  tmux kill-session -a
  647  tmux ls
  648  tmux kill-session -t ws6
  649  tmux ls
  650  tmux new -s a4
  651  cd ..
  652  cd worksheets
  653  ls
  654  cd worksheet5
  655  ls
  656  cat ws5.txt 
  657  cd ..
  658  cd worksheet6
  659  ls
  660  cat ws6.txt 
  661  exit
  662  vi test.txt
  663  grep sleep
  664  grep sleep test.txt
  665  grep -F sleep test.txt
  666  head -3 downloaded_tweets_extend_original_nolf2.tsv 
  667  head -3 downloaded_tweets_extend_nolf2.tsv 
  668  cd ..
  669  cd a3
  670  ls
  671  cat a3.txt 
  672  exit
  673  cd workplace/assignments/a4
  674  cut -d "	" -f4 downloaded_tweets_extend_nolf2.tsv | head -10
  675  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | head -10
  676  grep retweeed downloaded_tweets_extend_nolf2.tsv | head 20
  677  grep retweeed downloaded_tweets_extend_nolf2.tsv | head -20
  678  grep retweeted downloaded_tweets_extend_nolf2.tsv | head -20
  679  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | grep retweeted | head -20
  680  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | grep retweeted | sed "s/^.* id=//g" | head -20
  681  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | grep retweeted | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" | head -20
  682  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | grep retweeted | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" | sort -n | uniq -c | sort -rn |  head -10
  683  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | grep retweeted | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" | sort -n | uniq -c | sort -rn |  head -10 > top10retweeted.txt
  684  ls
  685  cut -d " " -f2  top10retweeted.txt 
  686  cat top10retweeted.txt 
  687  cut -d ' ' -f2 top10retweeted.txt 
  688  awk -F " " '{print $2}' top10retweeted.txt 
  689  awk -F " " 'BEGIN { ids[i++] = $2; for(i in ids) {print i}}' top10retweeted.txt 
  690  awk -F " " '{ ids[i++] = $2; for(i in ids) {print i}}' top10retweeted.txt 
  691  awk -F " " '{ ids[i++] = $2; for(i in ids) {print ids[i]}}' top10retweeted.txt 
  692  awk -F " " '{ ids[i++] = $2; for(i in ids) {fgrep ids[i]}}' top10retweeted.txt 
  693  awk -F " " '{ ids[i++] = $2; for(i in ids) {fgrep ids[i] downloaded_tweets_extend_original_nolf2.tsv}}' top10retweeted.txt 
  694  awk -F " " '{ ids[i++] = $2; for(i in ids) {`fgrep ids[i] downloaded_tweets_extend_original_nolf2.tsv`}}' top10retweeted.txt 
  695  awk -F " " '{ ids[i++] = $2; for(i in ids) "fgrep ids[i] downloaded_tweets_extend_original_nolf2.tsv"}' top10retweeted.txt 
  696  awk -F " " '{ ids[i++] = $2; for(i in ids) system("fgrep ids[i] downloaded_tweets_extend_original_nolf2.tsv")}' top10retweeted.txt 
  697  awk -F " " '{ ids[i++] = $2; for(i in ids) system("fgrep $ids[i] downloaded_tweets_extend_original_nolf2.tsv")}' top10retweeted.txt 
  698  awk -F " " '{ ids[i++] = $2; for(i in ids) system("fgrep $(ids[i]) downloaded_tweets_extend_original_nolf2.tsv")}' top10retweeted.txt 
  699  tmux 
  700  awk -F " " '{system("fgrep $2 downloaded_tweets_extend_original_nolf2.tsv")}' top10retweeted.txt 
  701  awk -F " " '{system("fgrep "$2" downloaded_tweets_extend_original_nolf2.tsv")}' top10retweeted.txt 
  702  head -2 downloaded_tweets_extend_original_nolf2.tsv 
  703  cat top10retweeted.txt 
  704  tmux new -s a4
  705  tmux ls
  706  tmux attach -t a4
  707  exit
  708  cd workplace/assignments/a4
  709  head -3 downloaded_tweets_extend_original_nolf2.tsv 
  710  cut -d "\t" -f5 downloaded_tweets_extend_original_nolf2.tsv 
  711  cut -d '\t' -f5 downloaded_tweets_extend_original_nolf2.tsv 
  712  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv 
  713  grep retweet downloaded_tweets_extend_original_nolf2.tsv 
  714  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv  | grep retweeted
  715  head -3 downloaded_tweets_extend_nolf2.tsv 
  716  grep retweeted downloaded_tweets_extend_nolf2.tsv | head -10
  717  grep retweeted downloaded_tweets_extend_nolf2.tsv | sed -d "	" -f5 | sed "s/^.* id=//g" | sed "s/ type=retweeted//g" | head -20
  718  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5 | sed "s/^.* id=//g" | sed "s/ type=retweeted//g" | head -20
  719  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5 | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" | head -20
  720  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5 | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" > retweetedIDs.txt
  721  kinit
  722  ccrkinit
  723  vi test
  724  ls
  725  rm test.txt
  726  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5 | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" > retweetedIDs.txt
  727  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5 | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" > retweetedIDs.csv
  728  df =h
  729  df -h
  730  cd ../../..
  731  cd datafiels
  732  cd datafiles
  733  ls
  734  rm downloaded_tweets_extend_nolf2.tsv 
  735  rm downloaded_tweets_extend_original_nolf2.tsv 
  736  cd..
  737  cd  ..
  738  cd workplace/assignments/a4
  739  ls
  740  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5 | sed "s/^.* id=//g" | sed "s/ type=retweeted\]//g" > retweetedIDs.csv
  741  ls
  742  head -5 retweetedIDs.csv 
  743  awk -F "/t" '{print $1}' retweededIDs.csv | head -5
  744  awk -F "/t" '{print $1}' retweetedIDs.csv | head -5
  745  awk -F "/t" '{retweets[i++]=$1} {for(i in retweets) {"fgrep "$1" retweetedIDs.csv | print $1 "," retweets[i]")} | head -5
  746  awk -F "/t" '{retweets[i++]=$1} {for(i in retweets) {"fgrep "$1" downloaded_tweets_extend_nolf2.tsv | print $1 "," retweets[i]")} retweetedIDs.csv | head -5
  747  awk -F "/t" '{retweets[i++]=$1} {for(i in retweets) {"fgrep "$1" downloaded_tweets_extend_nolf2.tsv | print $1 "," retweets[i]")}' retweetedIDs.csv | head -5
  748  rm retweetedIDs.csv 
  749  ls
  750  head -4 downloaded_tweets_extend_original_nolf2.tsv 
  751  grep retweeted downloaded_tweets_extend_original_nolf2.tsv 
  752  grep retweeted downloaded_tweets_extend_nolf2.tsv | head -5
  753  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,1 | head -5 
  754  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,1 | sed "s/^\[ id=//g" | head -5
  755  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,1 | sed "s/$(echo '\t')\[<ReferencedTweet id=//g" | head -5
  756  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,1 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | head -5
  757  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,1 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | sed "s/type=retweeted//g"  head -5
  758  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,1 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | sed "s/type=retweeted\]//g" | head -5
  759  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,1 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | sed "s/type=retweeted\]//g" > q1.csv
  760  cat q1.csv | cw -l
  761  cat q1.csv | cv -l
  762  cat q1.csv | wc -l
  763  ls
  764  awk -F, 
  765  awk -F, '{if($1!=$2) print $0}' q1.csv | sort -n | uniq -c | sort -k 1 -rn | head -9
  766  awk -F, '{if($1!=$2) print $0}' q1.csv | sort -n | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' 
  767  head -20 q1.csv 
  768  cat q1.csv |
  769  cat q1.csv | sort -n | uniq -c | sort -k 1 -rn | awk -F " " '{if($1>=3) {print}}' 
  770  awk -F "," '{if($1!=$2) print $1}' q1.csv | sort -n | uniq -c | sort -k1 -rn | awk -F " " '{if($1>=3) {print}}' 
  771  sed “s/,.*$//g” q1.csv > q2.csv
  772  sed "s/,.*$//g" q1.csv > q2.csv
  773  sort q2.csv | uniq -c | sort -k 1 -n -r
  774  sort q2.csv | uniq -c | sort -k 1 -n
  775  head -5 downloaded_tweets_extend_nolf2.tsv 
  776  grep retweeted downloaded_tweets_extend_nolf2.tsv  | head -5
  777  grep retweeted downloaded_tweets_extend_nolf2.tsv  | wc -l
  778  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,2 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | sed "s/type=retweeted\]//g" | head -5
  779  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f1,2 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | sed "s/type=retweeted\]//g" | head -5
  780  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f2,1 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | sed "s/type=retweeted\]//g" | head -5
  781  exit'
  782  exit
  783  cd workplace/assignments/a3
  784  ls
  785  cat a3.txt 
  786  cd /mnt/scratch
  787  ls
  788  cd obeda
  789  ;s
  790  ls
  791  cd jessie
  792  cd ..
  793  cd jessie
  794  ls
  795  cd ..
  796  cd guoman
  797  ls
  798  cd ..
  799  cd workplace/assignments/a3
  800  ls
  801  cat a3.txt 
  802  cd /
  803  cd home
  804  ls
  805  cd jessie
  806  cd chloe
  807  cd obeeda
  808  cd obeda
  809  man sort
  810  cd workplace/assignments/a3
  811  cat a3.txt 
  812  cd workplace/assignments/a4
  813  ls
  814  head -3 downloaded_tweets_extend_nolf2.tsv 
  815  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,2 | head -10
  816  grep retweeted downloaded_tweets_extend_nolf2.tsv | cut -d "	" -f5,2 | sed "s/$(echo '\t')\[<ReferencedTweet id=/,/g" | sed "s/ type=retweeted\]//g" | head -10
  817  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | head -10
  818  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=retweeted\]//g" | head -10
  819  ls
  820  rm q1.csv 
  821  rm q2.csv 
  822  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=retweeted\]//g" | wc -l
  823  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=retweeted\]//g" > q1.csv
  824  awk -F, '{if($1!=$2) {print $0}}' q1.csv | sort -k1 -n | uniq -c | sort -rn | head -10
  825  tmux ls
  826  awk -F, '{if($1!=$2) {print $0}}' q1.csv | sort -k1 -n | uniq -c | sort -rn | awk -F " " 'if($1>=3) {print}}' 
  827  awk -F, '{if($1!=$2) {print $0}}' q1.csv | sort -k1 -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print}}' 
  828  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -k1 -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' 
  829  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -k1 -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print}}' | head -10
  830  cat q1.csv | wc -l
  831  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -k1 -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' | wc -l
  832  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' | wc -l
  833  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print}}' | head -10
  834  fgrep 
  835  fgrep 1497678663046905863 q1.csv 
  836  fgrep 1516513505696010243 q1.csv 
  837  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' > tweetIDsSup3.txt
  838  cat tweetIDsSup3.txt | wc -l
  839  fgrep -f tweetIDsSup3.txt q1.csv | head -30
  840  fgrep -f tweetIDsSup3.txt q1.csv | sort | head -30
  841  cat tweetIDsSup3.txt | head -10
  842  fgrep -f tweetIDsSup3.txt q1.csv | sort | awk -F, $1!=$2 | head -30
  843  fgrep -f tweetIDsSup3.txt q1.csv | sort | awk -F, '$1!=$2' | head -30
  844  fgrep -f tweetIDsSup3.txt q1.csv | uniq -c | awk -F " " '{print $2}' | head -30
  845  awk 'system("fgrep "$1" q1.csv")' tweetIDsSup3.txt | head -20
  846  awk 'system("fgrep "$1" q1.csv")' tweetIDsSup3.txt | tail -20
  847  awk 'system("fgrep "$1" q1.csv")' tweetIDsSup3.txt > q2.csv
  848  cat q2.csv | wc -l
  849  cut -d "," -f1 q2.csv | uniq -c | head -10
  850  cut -d "," -f1 q2.csv | uniq -c | sort -k1 -rn | head -10
  851  cut -d "," -f1 q2.csv | uniq -c | cut -d " " -f1 | sort -k1 -n | head -10
  852  cut -d "," -f1 q2.csv | uniq -c | cut -d ' ' -f1 | sort -k1 -n | head -10
  853  cut -d "," -f1 q2.csv | uniq -c | cut -d ' ' -f1 | sort -n | head -10
  854  cut -d "," -f1 q2.csv | uniq -c | cut -d " " -f1 | sort -n | head -10
  855  cut -d "," -f1 q2.csv | uniq -c | cut -d " " -f1 | head -10
  856  cut -d "," -f1 q2.csv | uniq -c |  head -10
  857  cut -d "," -f1 q2.csv | uniq -c | cut -f1 |  head -10
  858  cut -d "," -f1 q2.csv | uniq -c | cut -f2 |  head -10
  859  cut -d "," -f1 q2.csv | uniq -c | awk -F " " 'print $1' |  head -10
  860  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' |  head -10
  861  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' | sort -n |  head -10
  862  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' | uniq -c | sort -n  |  head -10
  863  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' | uniq -c | sort -n  |  tail -10
  864  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' | uniq -c | sort -n  |  cat
  865  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' | uniq -c | sort -n > q3.txt
  866  /etc/gnuplot-5.4.4/src/gnuplot 
  867  ls
  868  head -3 downloaded_tweets_extend_original_nolf2.tsv 
  869  head -10 downloaded_tweets_extend_original_nolf2.tsv 
  870  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv | head -10
  871  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv | head -40
  872  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv | tail -40
  873  cut -d "	" -f5 downloaded_tweets_extend_original_nolf2.tsv | tail -80
  874  head -10 downloaded_tweets_extend_original_nolf2.tsv 
  875  head -10 q2.csv 
  876  cut -d "	" -f5 | head -20
  877  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv  | head -20
  878  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=replied_to//g" | head -5
  879  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=replied_to\]//g" | head -5
  880  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=replied_to\]//g" > q5_1
  881  ls
  882  rm q5_1 
  883  grep replied_to downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=replied_to\]//g" > q5_1.csv
  884  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' | head -10
  885  cat q5_1.csv | wc -l
  886  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | uniq -c | sort -rn | head -10
  887  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv |  head -10
  888  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | wc -l
  889  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | wc -l
  890  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | uniq -c | wc -l
  891  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | uniq -c | sort -rn |   head -10
  892  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | uniq -c | tail -10
  893  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' | head -10
  894  fgrep 1447870217615515653 q5_1.csv 
  895  awk -F, '{if($1!=$2) {print $1}}' q5_1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' > q5_2.txt
  896  awk 'sytem("fgrep "$1" q5_1.csv")' q5_2.txt
  897  awk 'system("fgrep "$1" q5_1.csv")' q5_2.txt
  898  awk 'system("fgrep "$1" q5_1.csv")' q5_2.txt > cluster_replies.txt
  899  rm cluster_replies.csv 
  900  awk 'system("fgrep "$1" q5_1.csv")' q5_2.txt > cluster_replies.csv
  901  ls
  902  head -20 q3.txt 
  903  head -20 q2.txt 
  904  head -20 q2.csv 
  905  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | gret retweeted | sed "s/^.* id=//g" | sed "s/type=retweeted\]//g" | sort -n | uniq -c | sort -rn | head -10 > top10retweeted.txt
  906  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | grep retweeted | sed "s/^.* id=//g" | sed "s/type=retweeted\]//g" | sort -n | uniq -c | sort -rn | head -10 > top10retweeted.txt
  907  head -10 top10retweeted.txt 
  908  awk -F " " '{system("fgrep "$2" downloaded_tweets_extend_original_nolf2.tsv")}' top10retweeted.txt 
  909  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=retweeted\]//g" > q1.csv
  910  head -5 q1.csv 
  911  cat q1.csv | wc -l
  912  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' > tweetIDsSup3.txt
  913  awk 'system("fgrep "$1" q1.csv")' tweetIDsSup3.txt > q2.csv
  914  head -10 q2.csv 
  915  cat q2.csv | wc -l
  916  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' | uniq -c | sort -n > q3.txt
  917  /etc/gnuplot-5.4.4/src/gnuplot 
  918  nano a4.txt 
  919  ne a4.txt
  920  vim a4.txt
  921  gnu a4.txt
  922  nano a4.txt 
  923  cat a4.txt 
  924  cat a4.txt | head -100
  925  2R
  926  exit
  927  cd workplace/assignments/a4
  928  ls
  929  rm histogram.svg 
  930  rm q1.csv 
  931  rm q2.csv 
  932  rm q3.txt 
  933  rm q5_1.csv 
  934  rm q5_2.txt 
  935  rm top10retweeted.txt 
  936  rm tweetIDsSup3.txt 
  937  ls
  938  script a4.txt
  939  cd workplace/assignments/a4
  940  ls
  941  cat a4.txt | head -80
  942  cat a4.txt | tail -80
  943  cd workplace/assignments/a4
  944  ls
  945  vi a4.txt 
  946  cat a4.txt 
  947  sed $'s/[^[:print:]\t]//g' a4.txt
  948  cut -d "	" -f5 downloaded_tweets_extend_nolf2.tsv | grep retweeted | sed "s/^.* id=//g" | sed "s/type=retweeted\]//g" | sort -n | uniq -c | sort -rn | head -10 > top10retweeted.txt
  949  head -10 top10retweeted.txt 
  950  awk -F " " '{system("fgrep "$2" downloaded_tweets_extend_original_nolf2.tsv")}' top10retweeted.txt 
  951  grep retweeted downloaded_tweets_extend_nolf2.tsv | awk -F "\t" '{print $5 "," $2}' | sed "s/\[<ReferencedTweet id=//g" | sed "s/ type=retweeted\]//g" > q1.csv
  952  head -5 q1.csv 
  953  cat q1.csv | wc -l
  954  awk -F, '{if($1!=$2) {print $1}}' q1.csv | sort -n | uniq -c | sort -rn | awk -F " " '{if($1>=3) {print $2}}' > tweetIDsSup3.txt
  955  awk 'system("fgrep "$1" q1.csv")' tweetIDsSup3.txt > q2.csv
  956  head -10 q2.csv 
  957  cut -d "," -f1 q2.csv | uniq -c | awk -F " " '{print $1}' | uniq -c | sort -n > q3.txt
  958  /etc/gnuplot-5.4.4/src/gnuplot 
  959  cd workplace/assignments/a4
  960  vi a4.txt
  961  nano a4.txt
  962  col -bp a4.txt | less -R
  963  col -bp typescript | less -R
  964  col -bp < typescript
  965  col -bp < a4
  966  col -bp typescript | less -Rol -bp typescript | less -R
  967  ls
  968  col -bp a4.txt | less -R
  969  cat typescript | perl -pe 's/\e([^\[\]]|\[.*?[a-zA-Z]|\].*?\a)//g'                  | col -b > typescript-processed
  970  cat a4.txt | perl -pe 's/\e([^\[\]]|\[.*?[a-zA-Z]|\].*?\a)//g' \ | col -b > a4.txt
  971  cat a4.txt | perl -pe 's/\e([^\[\]]|\[.*?[a-zA-Z]|\].*?\a)//g' | col -b > a4.txt
  972  cat a4.txt 
  973  a4.txt
  974  cat a4.txt
  975  ls
  976  cat typescript-processed 
  977  cat a4.txt 
  978  rm typescript-processed 
  979  rm a4.txt 
  980  script a4.txt
  981  vi a4.txt 
  982  cp a4.xt a4temp.txt
  983  cp a4.xt ./a4temp.txt
  984  cat a4.txt 
  985  vi a4
  986  vi a4.txt 
  987  cat a4.txt 
  988  head -10 q2.csv 
  989  head -10 q3.csv 
  990  head -10 q3.txt
  991  head -50 q2.csv 
  992  cat a4.txt 
  993  git add a4.txt
  994  git commit -m "submit assignment4"
  995  git push 
  996  git push
  997  ls
  998  head -3 amazon_reviews_us_Books_v1_02.tsv 
  999  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | wc -l
 1000  grep 1576734587 amazon_reviews_us_Books_v1_02.tsv | head -5
 1001  grep 1576734587 amazon_reviews_us_Books_v1_02.tsv | wc -l
 1002  head -1 amazon_reviews_us_Books_v1_02.tsv 
 1003  cut -d "	" -f14 amazon_reviews_us_Books_v1_02.tsv | head -4
 1004  head -2 amazon_reviews_us_Books_v1_02.tsv 
 1005  grep 0385730586 amazon_reviews_us_Books_v1_02.tsv | wc -k
 1006  grep 0385730586 amazon_reviews_us_Books_v1_02.tsv | wc -l
 1007  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | wc -l
 1008  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f14 | head -2
 1009  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f14 | head -10
 1010  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f14 | sed -e 's|<..*/>||g' -e 's/[,.;']//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/?//g' > output.txt
 1011  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f14 > review_body.txt
 1012  cat review_body | wc -l
 1013  review_body
 1014  cat review_body
 1015  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f14 | head -4
 1016  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f14 > review_body.txt
 1017  ls
 1018  cat review_body.txt | wc -l
 1019  head -3 review_body.txt 
 1020  sed -e 's|<..*/>||g' -e 's/[,.;']//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/?//g' review_body.txt > output.txt
 1021  ls
 1022  cat review_body | sed -e 's|<..*/>||g' -e 's/[,.;']//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/?//g' > output.txt
 1023  cat review_body.txt | sed -e 's|<..*/>||g' -e 's/[,.;']//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/?//g' > output.txt
 1024  sed -e 's|<..*/>||g' -e 's/[,.;']//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/?//g' review_body.txt > output.txt
review_body.txt
 1025  grep 0811828964 amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f14 > review_body
 1026  ls
 1027  sed -e 's|<..*/>||g' -e 's/[,.;']//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/?//g' review_body > output.txt
 1028  cat review_body | wc -l
 1029  sed -e 's|<..*/>||g' -e 's/[,.;']//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' review_body > output.txt
 1030  sed 's|<..*/>||g' | sed 's/[,.;']//g' | sed 's/it//g' | sed 's/and//g' | sed 's/or//g' | sed 's/if//g' | sed 's/in//g' | sed 's/?//g' review_body.txt > output.txt






 1031* sed 's|<..*/>||g' | sed 's/[,.;']//g' | sed 's/it//g' | sed 's/and//g' | sed 's/or//g'  review_body.txt > output.txt
 1032  sed 's|<..*/>||g' review_body.txt | sed 's/[,.;']//g' | sed 's/it//g' | sed 's/and//g' | sed 's/or//g' | sed 's/if//g' | sed 's/in//g' | sed 's/?//g' > output.txt

 1033  sed 's|<..*/>||g' review_body.txt | sed 's/[,.;']//g' | sed 's/it//g' | sed 's/and//g' | sed 's/or//g' | sed 's/if//g' | sed 's/in//g' | sed 's/?//g' > output.txt

 1034  sed 's|<..*/>||g' review_body.txt | sed 's/[,.;']//g' | sed 's/it//g' | sed 's/and//g' | sed 's/or//g' | sed 's/if//g' | sed 's/in//g' | sed 's/?//g' > output


 1035  ls
 1036  sed 's|<..*/>||g' review_body.txt | sed 's/[,.;']//g' | sed 's/it//g' | sed 's/and//g' | sed 's/or//g' | sed 's/if//g' | sed 's/in//g' | sed 's/?//g' review_body > output


 1037  sed -e 's|<..*/>||g' -e 's/[,.;]//g' -e 's/it//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/?//g' review_body > output.txt
 1038  head -10 output.txt 
 1039  ls
 1040  rm output.txt
 1041  rm review_body
 1042  rm review_body.txt 
 1043  script ws7.txt
 1044  history > cmds.log
